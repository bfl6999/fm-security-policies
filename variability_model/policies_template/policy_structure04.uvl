namespace Policies
imports
    k8s.Pod as Pod
    k8s.ServiceAccount as ServAcc
    k8s.RoleBinding as RoleBinding
    k8s.ClusterRoleBinding as ClusRole
    k8s.Service as Serv
    k8s.Ingress as Ingress
    k8s.Job as Job
    k8s.DaemonSet as DaemonSet
    k8s.Deployment as Deployment
    k8s.StatefulSet as StatefulSet
    k8s.Secret as Secret
    k8s.PersistentVolumeClaim as PersistVolumeClaim
    k8s.PodDisruptionBudget as PodDisrupBud
    k8s.CronJob as CronJob
    k8s.ReplicaSet as ReplicaSet
    k8s.ReplicationController as RepController
    k8s.Container as Container
    k8s.PodList as PodList
    k8s.PodTemplate as PodTemplate
    k8s.PodTemplateList as PodTemplateList
    k8s.PodTemplateSpec as PodTemplateSpec
    k8s.HorizontalPodAutoscaler as HorizontalPodAutoscaler
features
	PoliciesKubernetes {abstract}
		optional
			AWS_EKS_Best_Practices
				optional
					Require_aws_node_DaemonSet_use_IRSA {tool 'kyverno', severity 'medium', name 'require-aws-node-irsa', fields 'spec_template, spec_template_spec, spec_template_spec_serviceAccountName', kinds 'DaemonSet', doc 'According to EKS best practices, the aws-node DaemonSet is configured to use a role assigned to the EC2 instances to assign IPs to Pods This role includes several AWS managed policies that effectively allow all Pods running on a Node to attach/detach ENIs, assign/unassign IP addresses, or pull images from ECR Since this presents a risk to your cluster, it is recommended that you update the aws-node DaemonSet to use IRSA This policy ensures that the aws-node DaemonSet running in the kube-system Namespace is not still using the aws-node ServiceAccount', raw_source 'YAML'}
					Require_Encryption_with_AWS_LoadBalancers {tool 'kyverno', severity 'medium', name 'require-encryption-aws-loadbalancers', fields 'metadata_annotations, metadata_annotations_service_beta_kubernetes_io_aws_load_balancer_ssl_cert, spec_type', kinds 'Service', doc 'Services of type LoadBalancer when deployed inside AWS have support for transport encryption if it is enabled via an annotation This policy requires that Services of type LoadBalancer contain the annotation servicebetakubernetesio/aws-load-balancer-ssl-cert with some value', raw_source 'YAML'}
			Multi_Tenancy
				optional
					Disallow_Default_Namespace {tool 'kyverno', severity 'medium', name 'disallow-default-namespace', fields 'metadata_namespace', kinds 'Pod', doc 'Kubernetes Namespaces are an optional feature that provide a way to segment and isolate cluster resources across multiple applications and users As a best practice, workloads should be isolated with Namespaces Namespaces should be required and the default (empty) Namespace should not be used This policy validates that Pods specify a Namespace name other than default Rule auto-generation is disabled here due to Pod controllers need to specify the namespace field under the top-level metadata object and not at the Pod template level', raw_source 'YAML'}
			Best_Practices
				optional
					Require_Labels {tool 'kyverno', severity 'medium', name 'require-labels', fields 'metadata_labels, metadata_labels_app_kubernetes_io_name', kinds 'Pod, Label', doc 'Define and use labels that identify semantic attributes of your application or Deployment A common set of labels allows tools to work collaboratively, describing objects in a common manner that all tools can understand The recommended labels describe applications in a way that can be queried This policy validates that the label appkubernetesio/name is specified with some value', raw_source 'YAML'}
					Disallow_NodePort {tool 'kyverno', severity 'medium', name 'restrict-nodeport', fields 'spec_type', kinds 'Service', doc 'A Kubernetes Service of type NodePort uses a host port to receive traffic from any source A NetworkPolicy cannot be used to control traffic to host ports Although NodePort Services can be useful, their use must be limited to Services with additional upstream security checks This policy validates that any new Services do not use the NodePort type', raw_source 'YAML'}
					Restrict_External_IPs {tool 'kyverno', severity 'medium', name 'restrict-external-ips', fields 'spec_XexternalIPs', kinds 'Service', doc 'Service externalIPs can be used for a MITM attack (CVE-2020-8554) Restrict externalIPs or limit to a known set of addresses See: https:_githubcom/kyverno/kyverno/issues/1367 This policy validates that the externalIPs field is not set on a Service', raw_source 'YAML'}
					Restrict_Ingress_defaultBackend {tool 'kyverno', severity 'high', name 'restrict-ingress-defaultbackend', fields 'spec_XdefaultBackend', kinds 'Ingress', doc 'An Ingress with no rules sends all traffic to a single default backend The defaultBackend is conventionally a configuration option of the Ingress controller and is not specified in your Ingress resources If none of the hosts or paths match the HTTP request in the Ingress objects, the traffic is routed to your default backend In a multi-tenant environment, you want users to use explicit hosts, they should not be able to overwrite the global default backend service This policy prohibits the use of the defaultBackend field', raw_source 'YAML'}
			Best_Practices_EKS_Best_Practices_PSP_Migration
				optional
					Require_Read_Only_Root_Filesystem {tool 'kyverno', severity 'medium', name 'require-ro-rootfs', fields 'spec_containers', kinds 'Pod', doc 'A read-only root file system helps to enforce an immutable infrastructure strategy; the container only needs to write on the mounted volume that persists the state An immutable root filesystem can also prevent malicious binaries from writing to the host system This policy validates that containers define a securityContext with readOnlyRootFilesystem: true', raw_source 'YAML'}
			Best_Practices_EKS_Best_Practices
				optional
					Restrict_Image_Registries {tool 'kyverno', severity 'medium', name 'restrict-image-registries', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Images from unknown, public registries can be of dubious quality and may not be scanned and secured, representing a high degree of risk Requiring use of known, approved registries helps reduce threat exposure by ensuring image pulls only come from them This policy validates that container images only originate from the registry eufooio or bario Use of this policy requires customization to define your allowable registries', raw_source 'YAML'}
			Istio
				optional
					Enforce_Istio_Ambient_Mode {tool 'kyverno', severity 'medium', name 'enforce-ambient-mode-namespace', fields 'metadata_labels, metadata_labels_istio_io_dataplane_mode', kinds 'Namespace', doc 'In order for Istio to include namespaces in ambient mode, the label istioio/dataplane-mode must be set to ambient This policy ensures that all new Namespaces set istioio/dataplane-mode to ambient', raw_source 'YAML'}
					Enforce_Istio_Sidecar_Injection {tool 'kyverno', severity 'medium', name 'enforce-sidecar-injection-namespace', fields 'metadata_labels, metadata_labels_istio_injection', kinds 'Namespace', doc 'In order for Istio to inject sidecars to workloads deployed into Namespaces, the label istio-injection must be set to enabled This policy ensures that all new Namespaces set istio-inject to enabled', raw_source 'YAML'}
					Prevent_Disabling_Istio_Sidecar_Injection {tool 'kyverno', severity 'medium', name 'prevent-disabling-injection-pods', fields 'metadata_annotations, metadata_annotations_sidecar_istio_io_inject', kinds 'Pod', doc 'One way sidecar injection in an Istio service mesh may be accomplished is by defining an annotation at the Pod level Pods not receiving a sidecar cannot participate in the mesh thereby reducing visibility This policy ensures that Pods cannot set the annotation sidecaristioio/inject to a value of false', raw_source 'YAML'}
			Kubecost
				optional
					Require_Kubecost_Labels {tool 'kyverno', severity 'medium', name 'require-kubecost-labels', fields 'metadata_labels, metadata_labels_app, metadata_labels_department, metadata_labels_env, metadata_labels_owner, metadata_labels_team', kinds 'Pod, Label', doc 'Kubecost can use labels assigned to Pods in order to track and display cost allocation in a granular way These labels, which can be customized, can be used to organize and group workloads in different ways This policy requires that the labels owner, team, department, app, and env are all defined on Pods With Kyverno autogen enabled (absence of the annotation pod-policieskyvernoio/autogen-controllers=none), these labels will also be required for all Pod controllers', raw_source 'YAML'}
			Linkerd
				optional
					Prevent_Linkerd_Pod_Injection_Override {tool 'kyverno', severity 'medium', name 'prevent-linkerd-pod-injection-override', fields 'metadata_annotations, metadata_annotations_linkerd_io_inject', kinds 'Pod', doc 'Setting the annotation on a Pod (or its controller) linkerdio/inject to disabled may effectively disable mesh participation for that workload reducing security and visibility This policy prevents setting the annotation linkerdio/inject to disabled for Pods', raw_source 'YAML'}
					Require_Linkerd_Mesh_Injection {tool 'kyverno', severity 'medium', name 'require-linkerd-mesh-injection', fields 'metadata_annotations, metadata_annotations_linkerd_io_inject', kinds 'Namespace, Annotation', doc 'Sidecar proxy injection in Linkerd may be handled at the Namespace level by setting the annotation linkerdio/inject to enabled This policy enforces that all Namespaces contain the annotation linkerdio/inject set to enabled', raw_source 'YAML'}
			Other
				optional
					Block_Ephemeral_Containers {tool 'kyverno', severity 'medium', name 'block-ephemeral-containers', fields 'spec_XephemeralContainers', kinds 'Pod', doc 'Ephemeral containers, enabled by default in Kubernetes 123, allow users to use the kubectl debug functionality and attach a temporary container to an existing Pod This may potentially be used to gain access to unauthorized information executing inside one or more containers in that Pod This policy blocks the use of ephemeral containers', raw_source 'YAML'}
					Check_Environment_Variables {tool 'kyverno', severity 'medium', name 'check-env-vars', fields 'spec_containers', kinds 'Pod', doc 'Environment variables control many aspects of a container_s execution and are often the source of many different configuration settings Being able to ensure that the value of a specific environment variable either is or is not set to a specific string is useful to maintain such controls This policy checks every container to ensure that if the DISABLE_OPA environment variable is defined, it must not be set to a value of true', raw_source 'YAML'}
					Docker_Socket_Requires_Label {tool 'kyverno', severity 'medium', name 'docker-socket-check', fields 'metadata_labels, metadata_labels_allow_docker, spec_volumes', kinds 'Pod', doc 'Accessing a container engine_s socket is for highly specialized use cases and should generally be disabled If access must be granted, it should be done on an explicit basis This policy requires that, for any Pod mounting the Docker socket, it must have the label allow-docker set to true', raw_source 'YAML'}
					Limit_hostPath_PersistentVolumes_to_Specific_Directories {tool 'kyverno', severity 'medium', name 'limit-hostpath-type-pv', fields 'spec_hostPath, spec_hostPath_path', kinds 'PersistentVolume', doc 'hostPath persistentvolumes consume the underlying node_s file system If hostPath volumes are not to be universally disabled, they should be restricted to only certain host paths so as not to allow access to sensitive information This policy ensures the only directory that can be mounted as a hostPath volume is /data', raw_source 'YAML'}
					PodDisruptionBudget_maxUnavailable_Non_Zero {tool 'kyverno', name 'pdb-maxunavailable', fields 'spec_maxUnavailable', kinds 'PodDisruptionBudget', doc 'A PodDisruptionBudget which sets its maxUnavailable value to zero prevents all voluntary evictions including Node drains which may impact maintenance tasks This policy enforces that if a PodDisruptionBudget specifies the maxUnavailable field it must be greater than zero', raw_source 'YAML'}
					Prevent_cr8escape_CVE_2022_0811 {tool 'kyverno', severity 'high', name 'prevent-cr8escape', fields 'spec_securityContext, spec_securityContext_sysctls', kinds 'Pod', doc 'A vulnerability cr8escape (CVE-2022-0811) in CRI-O the container runtime engine underpinning Kubernetes allows attackers to escape from a Kubernetes container and gain root access to the host The recommended remediation is to disallow sysctl settings with + or = in their value', raw_source 'YAML'}
					Require_Annotations {tool 'kyverno', severity 'medium', name 'require-annotations', fields 'metadata_annotations, metadata_annotations_corp_org_department', kinds 'Pod, Annotation', doc 'Define and use annotations that identify semantic attributes of your application or Deployment A common set of annotations allows tools to work collaboratively, describing objects in a common manner that all tools can understand The recommended annotations describe applications in a way that can be queried This policy validates that the annotation corporg/department is specified with some value      ', raw_source 'YAML'}
					Require_Container_Port_Names {tool 'kyverno', severity 'medium', name 'require-container-port-names', fields 'spec_containers', kinds 'Pod', doc 'Containers may define ports on which they listen In addition to a port number, a name field may optionally be used Including a name makes it easier when defining Service resource definitions and others since the name may be referenced allowing the port number to change This policy requires that for every containerPort defined there is also a name specified      ', raw_source 'YAML'}
					Restrict_Node_Affinity {tool 'kyverno', severity 'medium', name 'restrict-node-affinity', fields 'spec_affinity, spec_affinity_XnodeAffinity', kinds 'Pod', doc 'Pods may use several mechanisms to prefer scheduling on a set of nodes, and nodeAffinity is one of them nodeAffinity uses expressions to select eligible nodes for scheduling decisions and may override intended placement options by cluster administrators This policy ensures that nodeAffinity is not used in a Pod spec', raw_source 'YAML'}
					Restrict_Service_Port_Range {tool 'kyverno', severity 'medium', name 'restrict-service-port-range', fields 'spec_ports', kinds 'Service', doc 'Services which are allowed to expose any port number may be able to impact other applications running on the Node which require them, or may make specifying security policy externally more challenging This policy enforces that only the port range 32000 to 33000 may be used for Service resources', raw_source 'YAML'}
			Security
				optional
					Deny_Secret_Service_Account_Token_Type {tool 'kyverno', severity 'medium', name 'deny-secret-service-account-token-type', kinds 'Secret, ServiceAccount', doc 'Before version 124, Kubernetes automatically generated Secret-based tokens  for ServiceAccounts When creating a Secret, you can specify its type using the  type field of the Secret resource  The type kubernetesio/service-account-token is used for legacy ServiceAccount tokens  These legacy Tokens can be of security concern and should be audited', raw_source 'YAML'}
					Restrict_Binding_to_Cluster_Admin {tool 'kyverno', severity 'medium', name 'restrict-binding-clusteradmin', fields 'roleRef_name', kinds 'RoleBinding, ClusterRoleBinding, RBAC', doc 'The cluster-admin ClusterRole allows any action to be performed on any resource in the cluster and its granting should be heavily restricted This policy prevents binding to the cluster-admin ClusterRole in RoleBinding or ClusterRoleBinding resources', raw_source 'YAML'}
					Restrict_Auto_Mount_of_Service_Account_Tokens_in_Service_Account {tool 'kyverno', severity 'medium', name 'restrict-sa-automount-sa-token', kinds 'Secret,ServiceAccount', doc 'Kubernetes automatically mounts ServiceAccount credentials in each ServiceAccount The ServiceAccount may be assigned roles allowing Pods to access API resources Blocking this ability is an extension of the least privilege best practice and should be followed if Pods do not need to speak to the API server to function This policy ensures that mounting of these ServiceAccount tokens is blocked      ', raw_source 'YAML'}
			Sample
				optional
					Disallow_Localhost_ExternalName_Services {tool 'kyverno', severity 'medium', name 'no-localhost-service', fields 'spec_externalName, spec_type', kinds 'Service', doc 'A Service of type ExternalName which points back to localhost can potentially be used to exploit vulnerabilities in some Ingress controllers This policy audits Services of type ExternalName if the externalName field refers to localhost', raw_source 'YAML'}
					Enforce_ReadWriteOncePod {tool 'kyverno', name 'readwriteonce-pod', fields 'spec_accessModes', kinds 'PersistentVolumeClaim', doc 'Some stateful workloads with multiple replicas only allow a single Pod to write to a given volume at a time Beginning in Kubernetes 122 and enabled by default in 127, a new setting called ReadWriteOncePod, available for CSI volumes only, allows volumes to be writable from only a single Pod For more information see the blog https:_kubernetesio/blog/2023/04/20/read-write-once-pod-access-mode-beta/ This policy enforces that the accessModes for a PersistentVolumeClaim be set to ReadWriteOncePod', raw_source 'YAML'}
					Require_Multiple_Replicas {tool 'kyverno', severity 'medium', name 'deployment-has-multiple-replicas', fields 'spec_replicas', kinds 'Deployment', doc 'Deployments with a single replica cannot be highly available and thus the application may suffer downtime if that one replica goes down This policy validates that Deployments have more than one replica', raw_source 'YAML'}
					Require_Images_Use_Checksums {tool 'kyverno', severity 'medium', name 'require-image-checksum', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Use of a SHA checksum when pulling an image is often preferable because tags are mutable and can be overwritten This policy checks to ensure that all images use SHA checksums rather than tags', raw_source 'YAML'}
					Restrict_Annotations {tool 'kyverno', name 'restrict-annotations', fields 'metadata_annotations, metadata_annotations_Xfluxcd_io_*', kinds 'Pod, Annotation', doc 'Some annotations control functionality driven by other cluster-wide tools and are not normally set by some class of users This policy prevents the use of an annotation beginning with fluxcdio/ This can be useful to ensure users either don_t set reserved annotations or to force them to use a newer version of an annotation', raw_source 'YAML'}
					Restrict_control_plane_scheduling {tool 'kyverno', name 'restrict-controlplane-scheduling', fields 'spec_tolerations', kinds 'Pod', doc 'Scheduling non-system Pods to control plane nodes (which run kubelet) is often undesirable because it takes away resources from the control plane components and can represent a possible security threat vector This policy prevents users from setting a toleration in a Pod spec which allows running on control plane nodes with the taint key node-rolekubernetesio/master', raw_source 'YAML'}
					Restrict_Ingress_Classes {tool 'kyverno', severity 'medium', name 'restrict-ingress-classes', fields 'metadata_annotations, metadata_annotations_kubernetes_io_ingress_class', kinds 'Ingress', doc 'Ingress classes should only be allowed which match up to deployed Ingress controllers in the cluster Allowing users to define classes which cannot be satisfied by a deployed Ingress controller can result in either no or undesired functionality This policy checks Ingress resources and only allows those which define HAProxy or nginx in the respective annotation This annotation has largely been replaced as of Kubernetes 118 with the IngressClass resource', raw_source 'YAML'}
					Disallow_Service_Type_LoadBalancer {tool 'kyverno', severity 'medium', name 'no-loadbalancer-service', fields 'spec_type', kinds 'Service', doc 'Especially in cloud provider environments, a Service having type LoadBalancer will cause the provider to respond by creating a load balancer somewhere in the customer account This adds cost and complexity to a deployment Without restricting this ability, users may easily overrun established budgets and security practices set by the organization This policy restricts use of the Service type LoadBalancer', raw_source 'YAML'}
					Restrict_node_selection {tool 'kyverno', name 'restrict-node-selection', fields 'spec_XnodeName, spec_XnodeSelector', kinds 'Pod', doc 'The Kubernetes scheduler uses complex logic to determine the optimal placement for new Pods Users who have access to set certain fields in a Pod spec may sidestep this logic which in many cases is undesirable This policy prevents users from targeting specific Nodes for scheduling of Pods by prohibiting the use of the nodeSelector and nodeName fields Note that this policy is only designed to work on initial creation and not in background mode', raw_source 'YAML'}
					Validate_User_ID_Group_ID_and_FS_Group {tool 'kyverno', severity 'medium', name 'validate-userid-groupid-fsgroup', fields 'spec_securityContext, spec_securityContext_fsGroup, spec_securityContext_runAsGroup, spec_securityContext_runAsUser', kinds 'Pod', doc 'All processes inside a Pod can be made to run with specific user and groupID by setting runAsUser and runAsGroup respectively fsGroup can be specified to make sure any file created in the volume will have the specified groupID This policy validates that these fields are set to the defined values', raw_source 'YAML'}
			Multi_Tenancy_EKS_Best_Practices
				optional
					Require_Pod_priorityClassName {tool 'kyverno', severity 'medium', name 'require-pod-priorityclassname', fields 'spec_priorityClassName', kinds 'Pod', doc 'A Pod may optionally specify a priorityClassName which indicates the scheduling priority relative to others This requires creation of a PriorityClass object in advance With this created, a Pod may set this field to that value In a multi-tenant environment, it is often desired to require this priorityClassName be set to make certain tenant scheduling guarantees This policy requires that a Pod defines the priorityClassName field with some value', raw_source 'YAML'}
			Other_Multi_Tenancy
				optional
					Require_StorageClass {tool 'kyverno', severity 'medium', name 'require-storageclass', fields 'spec_storageClassName, spec_volumeClaimTemplates', kinds 'PersistentVolumeClaim, StatefulSet', doc 'PersistentVolumeClaims (PVCs) and StatefulSets may optionally define a StorageClass to dynamically provision storage In a multi-tenancy environment where StorageClasses are far more common, it is often better to require storage only be provisioned from these StorageClasses This policy requires that PVCs and StatefulSets containing volumeClaimTemplates define the storageClassName field with some value', raw_source 'YAML'}
					Restrict_StorageClass {tool 'kyverno', severity 'medium', name 'restrict-storageclass', kinds 'StorageClass', doc 'StorageClasses allow description of custom classes of storage offered by the cluster, based on quality-of-service levels, backup policies, or custom policies determined by the cluster administrators For shared StorageClasses in a multi-tenancy environment, a reclaimPolicy of Delete should be used to ensure a PersistentVolume cannot be reused across Namespaces This policy requires StorageClasses set a reclaimPolicy of Delete', raw_source 'YAML'}
			Sample_EKS_Best_Practices
				optional
					Restrict_Auto_Mount_of_Service_Account_Tokens {tool 'kyverno', severity 'medium', name 'restrict-automount-sa-token', fields 'spec_automountServiceAccountToken', kinds 'Pod,ServiceAccount', doc 'Kubernetes automatically mounts ServiceAccount credentials in each Pod The ServiceAccount may be assigned roles allowing Pods to access API resources Blocking this ability is an extension of the least privilege best practice and should be followed if Pods do not need to speak to the API server to function This policy ensures that mounting of these ServiceAccount tokens is blocked', raw_source 'YAML'}
			Security_EKS_Best_Practices
				optional
					Restrict_Binding_System_Groups {tool 'kyverno', severity 'medium', name 'restrict-binding-system-groups', kinds 'RoleBinding, ClusterRoleBinding, RBAC', doc 'Certain system groups exist in Kubernetes which grant permissions that are used for certain system-level functions yet typically never appropriate for other users This policy prevents creating bindings to some of these groups including system:anonymous, system:unauthenticated, and system:masters', raw_source 'YAML'}
			Pod_Security_Standards_Baseline
				optional
					Disallow_Host_Namespaces {tool 'kyverno', severity 'medium', name 'disallow-host-namespaces', fields 'spec_hostIPC, spec_hostNetwork, spec_hostPID', kinds 'Pod', doc 'Host namespaces (Process ID namespace, Inter-Process Communication namespace, and network namespace) allow access to shared information and can be used to elevate privileges Pods should not be allowed access to host namespaces This policy ensures fields which make use of these host namespaces are unset or set to false', raw_source 'YAML'}
					Disallow_hostPath {tool 'kyverno', severity 'medium', name 'disallow-host-path', fields 'spec_volumes', kinds 'Pod,Volume', doc 'HostPath volumes let Pods use host directories and volumes in containers Using host resources can be used to access shared data or escalate privileges and should not be allowed This policy ensures no hostPath volumes are in use', raw_source 'YAML'}
					Disallow_hostPorts_Range_Alternate {tool 'kyverno', severity 'medium', name 'disallow-host-ports-range', kinds 'Pod', doc 'Access to host ports allows potential snooping of network traffic and should not be allowed by requiring host ports be undefined (recommended) or at minimum restricted to a known list This policy ensures the hostPort field, if defined, is set to either a port in the specified range or to a value of zero This policy is mutually exclusive of the disallow-host-ports policy Note that Kubernetes Pod Security Admission does not support the host port range rule', raw_source 'YAML'}
					Disallow_hostPorts {tool 'kyverno', severity 'medium', name 'disallow-host-ports', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Access to host ports allows potential snooping of network traffic and should not be allowed, or at minimum restricted to a known list This policy ensures the hostPort field is unset or set to 0 ', raw_source 'YAML'}
					Disallow_hostProcess {tool 'kyverno', severity 'medium', name 'disallow-host-process', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Windows pods offer the ability to run HostProcess containers which enables privileged access to the Windows node Privileged access to the host is disallowed in the baseline policy HostProcess pods are an alpha feature as of Kubernetes v122 This policy ensures the hostProcess field, if present, is set to false', raw_source 'YAML'}
					Disallow_Privileged_Containers {tool 'kyverno', severity 'medium', name 'disallow-privileged-containers', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Privileged mode disables most security mechanisms and must not be allowed This policy ensures Pods do not call for privileged mode', raw_source 'YAML'}
					Disallow_procMount {tool 'kyverno', severity 'medium', name 'disallow-proc-mount', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'The default /proc masks are set up to reduce attack surface and should be required This policy ensures nothing but the default procMount can be specified Note that in order for users to deviate from the Default procMount requires setting a feature gate at the API server', raw_source 'YAML'}
					Restrict_AppArmor {tool 'kyverno', severity 'medium', name 'restrict-apparmor-profiles', fields 'metadata_annotations, metadata_annotations_container_apparmor_security_beta_kubernetes_io_*', kinds 'Pod, Annotation', doc 'On supported hosts, the _runtime/default_ AppArmor profile is applied by default The default policy should prevent overriding or disabling the policy, or restrict overrides to an allowed set of profiles This policy ensures Pods do not specify any other AppArmor profiles than runtime/default or localhost/*', raw_source 'YAML'}
					Restrict_Seccomp {tool 'kyverno', severity 'medium', name 'restrict-seccomp', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers, spec_securityContext, spec_securityContext_seccompProfile, spec_securityContext_seccompProfile_type', kinds 'Pod', doc 'The seccomp profile must not be explicitly set to Unconfined This policy,  requiring Kubernetes v119 or later, ensures that seccomp is unset or  set to RuntimeDefault or Localhost', raw_source 'YAML'}
			Pod_Security_Standards_Restricted
				optional
					Disallow_Privilege_Escalation {tool 'kyverno', severity 'medium', name 'disallow-privilege-escalation', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers', kinds 'Pod', doc 'Privilege escalation, such as via set-user-ID or set-group-ID file mode, should not be allowed This policy ensures the allowPrivilegeEscalation field is set to false', raw_source 'YAML'}
					Require_Run_As_Non_Root_User {tool 'kyverno', severity 'medium', name 'require-run-as-non-root-user', fields 'spec_containers, spec_ephemeralContainers, spec_initContainers, spec_securityContext, spec_securityContext_runAsUser', kinds 'Pod', doc 'Containers must be required to run as non-root users This policy ensures runAsUser is either unset or set to a number greater than zero', raw_source 'YAML'}
			Pod_Security_Admission_EKS_Best_Practices
				optional
					Add_PSA_Namespace_Reporting {tool 'kyverno', severity 'medium', name 'add-psa-namespace-reporting', fields 'metadata_labels, metadata_labels_pod_security_kubernetes_io_*', kinds 'Namespace', doc 'This policy is valuable as it ensures that all namespaces within a Kubernetes  cluster are labeled with Pod Security Admission (PSA) labels, which are crucial for defining security levels and ensuring that pods within a namespace operate  under the defined Pod Security Standard (PSS) By enforcing namespace labeling, This policy audits namespaces to verify the presence of PSA labels  If a namespace is found without the required labels, it generates and maintain  and ClusterPolicy Report in default namespace  This helps administrators identify namespaces that do not comply with the  organization_s security practices and take appropriate action to rectify the  situation', raw_source 'YAML'}
			PSP_Migration
				optional
					Check_supplementalGroups {tool 'kyverno', severity 'medium', name 'psp-check-supplemental-groups', fields 'spec_securityContext, spec_securityContext_supplementalGroups', kinds 'Pod', doc 'Supplemental groups control which group IDs containers add and can coincide with restricted groups on the host Pod Security Policies (PSP) allowed a range of these group IDs to be specified which were allowed This policy ensures any Pod may only specify supplementalGroup IDs between 100-200 or 500-600', raw_source 'YAML'}
			Windows_Security
				optional
					Require_Run_As_ContainerUser_Windows {tool 'kyverno', severity 'medium', name 'require-run-as-containeruser', fields 'spec_containers, spec_initContainers, spec_securityContext, spec_securityContext_windowsOptions, spec_securityContext_windowsOptions_runAsUserName', kinds 'Pod', doc 'Containers must be required to run as ContainerUser This policy ensures that the fields  specsecurityContextwindowsOptionsrunAsUserName, speccontainers[*]securityContextwindowsOptionsrunAsUserName,  specinitContainers[*]securityContextwindowsOptionsrunAsUserName, and  is either unset or set to ContainerUser', raw_source 'YAML'}
			OPAConstraints {abstract}
				optional
					no_shared_ipc_namespace {tool 'trivy', severity 'high', name 'no-shared-ipc-namespace', fields 'spec_template_spec_hostIPC', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Sharing the host_s IPC namespace allows container processes to communicate with processes on the host', RecommendedAction 'Do not set _spectemplatespechostIPC_ to true', raw_source 'OPA-Rego'}
					no_host_network {tool 'trivy', severity 'high', name 'no-host-network', fields 'spec_template_spec_hostNetwork', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Sharing the host_s network namespace permits processes in the pod to communicate with processes bound to the host_s loopback adapter', RecommendedAction 'Do not set _spectemplatespechostNetwork_ to true', raw_source 'OPA-Rego'}
					no_host_pid {tool 'trivy', severity 'high', name 'no-host-pid', fields 'spec_template_spec_hostPID', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Sharing the host_s PID namespace allows visibility on host processes, potentially leaking information such as environment variables and configuration', RecommendedAction 'Do not set _spectemplatespechostPID_ to true', raw_source 'OPA-Rego'}
					no_docker_sock_mount {tool 'trivy', severity 'high', name 'no-docker-sock-mount', fields 'volumes_hostPath_path', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Mounting dockersock from the host can give the container full root access to the host', RecommendedAction 'Do not specify /var/run/dockersocket in _spectemplatevolumeshostPathpath_', raw_source 'OPA-Rego'}
					no_privileged_containers {tool 'trivy', severity 'high', name 'no-privileged-containers', fields 'securityContext_privileged', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Privileged containers share namespaces with the host system and do not offer any security They should be used exclusively for system containers that require high privileges', RecommendedAction 'Change _containers[]securityContextprivileged_ to _false_', raw_source 'OPA-Rego'}
					no_auto_mount_service_token {tool 'trivy', severity 'medium', name 'no-auto-mount-service-token', fields 'spec_automountServiceAccountToken', doc 'ensure that Pod specifications disable the secret token being mounted by setting automountServiceAccountToken: false', RecommendedAction 'Disable the mounting of service account secret token by setting automountServiceAccountToken to false', raw_source 'OPA-Rego'}
					no_root {tool 'trivy', severity 'medium', name 'no-root', fields 'securityContext_runAsNonRoot', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Force the running image to run as a non-root user to ensure least privileges', RecommendedAction 'Set _containers[]securityContextrunAsNonRoot_ to true', raw_source 'OPA-Rego'}
					use_high_gid {tool 'trivy', severity 'low', name 'use-high-gid', fields 'securityContext_runAsGroup', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Force the container to run with group ID > 10000 to avoid conflicts with the host_s user table', RecommendedAction 'Set _containers[]securityContextrunAsGroup_ to an integer > 10000', raw_source 'OPA-Rego'}
					use_high_uid {tool 'trivy', severity 'low', name 'use-high-uid', fields 'securityContext_runAsUser', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'Force the container to run with user ID > 10000 to avoid conflicts with the host_s user table', RecommendedAction 'Set _containers[]securityContextrunAsUser_ to an integer > 10000', raw_source 'OPA-Rego'}
					no_sysadmin_capability {tool 'trivy', severity 'high', name 'no-sysadmin-capability', fields 'container_securityContext_capabilities_add', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'SYS_ADMIN gives the processes running inside the container privileges that are equivalent to root', RecommendedAction 'Remove the SYS_ADMIN capability from _containers[]securityContextcapabilitiesadd_', raw_source 'OPA-Rego'}
					no_sysmodule_capability {tool 'trivy', severity 'high', name 'no-sysmodule-capability', fields 'container_securityContext_capabilities_add', kinds 'cronjob, daemonset, deployment, deploymentconfig, job, pod, replicaset, replicationcontroller, statefulset', doc 'The SYS_MODULE capability grants attackers the ability to install and remove kernel modules, posing serious security risks', RecommendedAction 'To mitigate potential security risks, it is strongly recommended to remove the SYS_MODULE capability from _containers[]securityContextcapabilitiesadd_ It is advisable to follow the practice of dropping all capabilities and only adding the necessary ones', raw_source 'OPA-Rego'}
			PolarisConstraints {abstract}
				optional
					cpuLimitsMissing {tool 'Polaris', severity 'warning', name_field 'cpuLimitsMissing', kinds 'Container', doc 'CPU limits should be set', category 'Efficiency', raw_source 'YAML with dinamic JSON'}
					cpuRequestsMissing {tool 'Polaris', severity 'warning', name_field 'cpuRequestsMissing', kinds 'Container', doc 'CPU requests should be set', category 'Efficiency', raw_source 'YAML with dinamic JSON'}
					memoryLimitsMissing {tool 'Polaris', severity 'warning', name_field 'memoryLimitsMissing', kinds 'Container', doc 'Memory limits should be set', category 'Efficiency', raw_source 'YAML with dinamic JSON'}
					memoryRequestsMissing {tool 'Polaris', severity 'warning', name_field 'memoryRequestsMissing', kinds 'Container', doc 'Memory requests should be set', category 'Efficiency', raw_source 'YAML with dinamic JSON'}
					deploymentMissingReplicas {tool 'Polaris', severity 'warning', name_field 'deploymentMissingReplicas', kinds 'Controller', doc 'Only one replica is scheduled', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					hpaMaxAvailability {tool 'Polaris', severity 'warning', name_field 'hpaMaxAvailability', kinds 'autoscaling/HorizontalPodAutoscaler', doc 'HPA maxReplicas and minReplicas should be different', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					hpaMinAvailability {tool 'Polaris', severity 'warning', name_field 'hpaMinAvailability', kinds 'autoscaling/HorizontalPodAutoscaler', doc 'HPA minReplicas should be 2 or more', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					livenessProbeMissing {tool 'Polaris', severity 'warning', name_field 'livenessProbeMissing', kinds 'Container', doc 'Liveness probe should be configured', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					metadataAndInstanceMismatched {tool 'Polaris', severity 'warning', name_field 'metadataAndInstanceMismatched', kinds 'Controller', doc 'Label appkubernetesio/instance must match metadataname', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					priorityClassNotSet {tool 'Polaris', severity 'warning', name_field 'priorityClassNotSet', kinds 'PodSpec', doc 'Priority class should be set', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					pullPolicyNotAlways {tool 'Polaris', severity 'warning', name_field 'pullPolicyNotAlways', kinds 'Container', doc 'Image pull policy should be Always', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					readinessProbeMissing {tool 'Polaris', severity 'warning', name_field 'readinessProbeMissing', kinds 'Container', doc 'Readiness probe should be configured', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					tagNotSpecified {tool 'Polaris', severity 'danger', name_field 'tagNotSpecified', kinds 'Container', doc 'Image tag should be specified', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					topologySpreadConstraint {tool 'Polaris', severity 'warning', name_field 'topologySpreadConstraint', kinds 'PodSpec', doc 'Pod should be configured with a valid topology spread constraint', category 'Reliability', raw_source 'YAML with dinamic JSON'}
					automountServiceAccountToken {tool 'Polaris', severity 'warning', name_field 'automountServiceAccountToken', kinds 'PodSpec', doc 'The ServiceAccount will be automounted', category 'Security', raw_source 'YAML with dinamic JSON'}
					dangerousCapabilities {tool 'Polaris', severity 'danger', name_field 'dangerousCapabilities', kinds 'Container', doc 'Container should not have dangerous capabilities', category 'Security', raw_source 'YAML with dinamic JSON'}
					hostIPCSet {tool 'Polaris', severity 'danger', name_field 'hostIPCSet', kinds 'PodSpec', doc 'Host IPC should not be configured', category 'Security', raw_source 'YAML with dinamic JSON'}
					hostNetworkSet {tool 'Polaris', severity 'danger', name_field 'hostNetworkSet', kinds 'PodSpec', doc 'Host network should not be configured', category 'Security', raw_source 'YAML with dinamic JSON'}
					hostPIDSet {tool 'Polaris', severity 'danger', name_field 'hostPIDSet', kinds 'PodSpec', doc 'Host PID should not be configured', category 'Security', raw_source 'YAML with dinamic JSON'}
					hostPortSet {tool 'Polaris', severity 'warning', name_field 'hostPortSet', kinds 'Container', doc 'Host port should not be configured', category 'Security', raw_source 'YAML with dinamic JSON'}
					insecureCapabilities {tool 'Polaris', severity 'warning', name_field 'insecureCapabilities', kinds 'Container', doc 'Container should not have insecure capabilities', category 'Security', raw_source 'YAML with dinamic JSON'}
					linuxHardening {tool 'Polaris', severity 'danger', name_field 'linuxHardening', kinds 'Container', doc 'Use one of AppArmor, Seccomp, SELinux, or dropping Linux Capabilities to restrict containers using unwanted privileges', category 'Security', raw_source 'YAML with dinamic JSON'}
					notReadOnlyRootFilesystem {tool 'Polaris', severity 'warning', name_field 'notReadOnlyRootFilesystem', kinds 'PodSpec', doc 'Filesystem should be read only', category 'Security', raw_source 'YAML with dinamic JSON'}
					privilegeEscalationAllowed {tool 'Polaris', severity 'danger', name_field 'privilegeEscalationAllowed', kinds 'PodSpec', doc 'Privilege escalation should not be allowed', category 'Security', raw_source 'YAML with dinamic JSON'}
					procMount {tool 'Polaris', severity 'warning', name_field 'procMount', kinds 'PodSpec', doc 'Proc mount must not be changed from the default', category 'Security', raw_source 'YAML with dinamic JSON'}
					runAsPrivileged {tool 'Polaris', severity 'danger', name_field 'runAsPrivileged', kinds 'PodSpec', doc 'Should not be running as privileged', category 'Security', raw_source 'YAML with dinamic JSON'}
					runAsRootAllowed {tool 'Polaris', severity 'danger', name_field 'runAsRootAllowed', kinds 'PodSpec', doc 'Should not be allowed to run as root', category 'Security', raw_source 'YAML with dinamic JSON'}
					tlsSettingsMissing {tool 'Polaris', severity 'warning', name_field 'tlsSettingsMissing', kinds 'networking_k8s_io/Ingress', doc 'Ingress does not have TLS configured', category 'Security', raw_source 'YAML with dinamic JSON'}
			GatekeeeperConstraints {abstract}
				optional
					k8spsphostfilesystem {tool 'Gatekeeper', severity 'undefined', category 'Host_Filesystem', kinds 'Pod', doc 'Controls usage of the host filesystem Corresponds to the allowedHostPaths field in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems'}
					k8spsphostnamespace {tool 'Gatekeeper', severity 'undefined', category 'Host_Namespace', kinds 'Pod', doc 'Disallows sharing of host PID and IPC namespaces by pod containers Corresponds to the hostPID and hostIPC fields in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#host-namespaces'}
					k8spsphostnetworkingports {tool 'Gatekeeper', severity 'undefined', category 'Host_Networking_Ports', kinds 'Pod', doc 'Controls usage of host network namespace by pod containers HostNetwork verification happens without exception for exemptImages Specific ports must be specified Corresponds to the hostNetwork and hostPorts fields in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#host-namespaces'}
					k8spspprivilegedcontainer {tool 'Gatekeeper', severity 'undefined', category 'Privileged_Container', kinds 'Pod', doc 'Controls the ability of any container to enable privileged mode Corresponds to the privileged field in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#privileged'}
					k8spspreadonlyrootfilesystem {tool 'Gatekeeper', severity 'undefined', category 'Read_Only_Root_Filesystem', kinds 'Pod', doc 'Requires the use of a read-only root file system by pod containers Corresponds to the readOnlyRootFilesystem field in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems'}
					k8spspvolumetypes {tool 'Gatekeeper', severity 'undefined', category 'Volume_Types', kinds 'Pod', doc 'Restricts mountable volume types to those specified by the user Corresponds to the volumes field in a PodSecurityPolicy For more information, see https:_kubernetesio/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems'}
			Pod.PodFeatures
			ServAcc.ServiceAccountFeatures
			RoleBinding.RoleBindingFeatures
			ClusRole.ClusterRoleBindingFeatures
			Serv.ServiceFeatures
			Ingress.IngressFeatures
			Job.JobFeatures
			DaemonSet.DaemonSetFeatures
			Deployment.DeploymentFeatures
			StatefulSet.StatefulSetFeatures
			Secret.SecretFeatures
			PersistVolumeClaim.PersistentVolumeClaimFeatures
			PodDisrupBud.PodDisruptionBudgetFeatures
			CronJob.CronJobFeatures
			ReplicaSet.ReplicaSetFeatures
			RepController.ReplicationControllerFeatures
			Container.ContainerFeatures
			PodList.PodListFeatures
			PodTemplate.PodTemplateFeatures
			PodTemplateList.PodTemplateListFeatures
			PodTemplateSpec.PodTemplateSpecFeatures
			HorizontalPodAutoscaler.HorizontalPodAutoscalerFeatures
constraints
	Require_aws_node_DaemonSet_use_IRSA => DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_serviceAccountName != 'aws-node'
	Require_Encryption_with_AWS_LoadBalancers => (Serv.io_k8s_api_core_v1_Service_metadata_annotations_KeyMap == 'service_beta_kubernetes_io/aws-load-balancer-ssl-cert' & Serv.io_k8s_api_core_v1_Service_metadata_annotations_ValueMap == '?*') | (Serv.io_k8s_api_core_v1_Service_spec_type_LoadBalancer)
	Disallow_Default_Namespace => (Pod.io_k8s_api_core_v1_Pod_metadata_namespace != 'default' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_metadata_namespace != 'default' & Deployment.io_k8s_api_apps_v1_Deployment_metadata_namespace != 'default' & Job.io_k8s_api_batch_v1_Job_metadata_namespace != 'default' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_metadata_namespace != 'default')
	Require_Labels => (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'app_kubernetes_io/name' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*')
	Require_Read_Only_Root_Filesystem => Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_readOnlyRootFilesystem
	Restrict_Image_Registries => (Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_image == 'eu_foo_io/* | bar_io/*' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_image == 'eu_foo_io/* | bar_io/*' & Pod.io_k8s_api_core_v1_Pod_spec_containers_image == 'eu_foo_io/* | bar_io/*')
	Disallow_NodePort => !Serv.io_k8s_api_core_v1_Service_spec_type_NodePort
	Restrict_External_IPs => !Serv.io_k8s_api_core_v1_Service_spec_externalIPs
	Enforce_Istio_Ambient_Mode => (Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_KeyMap == 'istio_io/dataplane-mode' & Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_ValueMap == 'ambient')
	Enforce_Istio_Sidecar_Injection => (Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_KeyMap == 'istio-injection' & Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_ValueMap == 'enabled')
	Prevent_Disabling_Istio_Sidecar_Injection => (Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'sidecar_istio_io/inject' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap != 'false')
	Require_Kubecost_Labels => (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'owner' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*') | (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'team' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*') | (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'department' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*') | (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'app' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*') | (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'env' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap == '?*')
	Prevent_Linkerd_Pod_Injection_Override => (Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'linkerd_io/inject' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap != 'disabled')
	Require_Linkerd_Mesh_Injection => (Kubernetes.io_k8s_api_core_v1_Namespace_metadata_annotations_KeyMap == 'linkerd_io/inject' & Kubernetes.io_k8s_api_core_v1_Namespace_metadata_annotations_ValueMap == 'enabled')
	Block_Ephemeral_Containers => !Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers
	Check_Environment_Variables => (Pod.io_k8s_api_core_v1_Pod_spec_containers_name == '*' & Pod.io_k8s_api_core_v1_Pod_spec_containers_env_name == 'DISABLE_OPA' & Pod.io_k8s_api_core_v1_Pod_spec_containers_env_value != 'true')
	Deny_Secret_Service_Account_Token_Type => Secret.io_k8s_api_core_v1_Secret_type != 'kubernetes_io/service-account-token'
	Disallow_Localhost_ExternalName_Services => (Serv.io_k8s_api_core_v1_Service_spec_type_ExternalName & Serv.io_k8s_api_core_v1_Service_spec_externalName != 'localhost')
	Docker_Socket_Requires_Label => (Pod.io_k8s_api_core_v1_Pod_metadata_labels_KeyMap == 'allow-docker' & Pod.io_k8s_api_core_v1_Pod_metadata_labels_ValueMap) | (Pod.io_k8s_api_core_v1_Pod_spec_volumes_hostPath_path == '/var/run/docker_sock')
	Enforce_ReadWriteOncePod => PersistVolumeClaim.io_k8s_api_core_v1_PersistentVolumeClaim_spec_accessModes_StringValue == 'ReadWriteOncePod'
	Limit_hostPath_PersistentVolumes_to_Specific_Directories => Kubernetes.io_k8s_api_core_v1_PersistentVolume_spec_hostPath_path == '/data*'
	PodDisruptionBudget_maxUnavailable_Non_Zero => PodDisrupBud.io_k8s_api_policy_v1_PodDisruptionBudget_spec_maxUnavailable_asInteger > 0
	Prevent_cr8escape_CVE_2022_0811 => Pod.io_k8s_api_core_v1_Pod_spec_securityContext_sysctls_value != '*+* & *=*'
	Require_Annotations => (Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'corp_org/department' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap == '?*')
	Require_Container_Port_Names => (Pod.io_k8s_api_core_v1_Pod_spec_containers_name == '*' & Pod.io_k8s_api_core_v1_Pod_spec_containers_ports_name == '*')
	Require_Multiple_Replicas => Deployment.io_k8s_api_apps_v1_Deployment_spec_replicas > 1
	Require_Images_Use_Checksums => (Pod.io_k8s_api_core_v1_Pod_spec_containers_image == '*@*' & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_image == '*@*' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_image == '*@*')
	Require_Pod_priorityClassName => Pod.io_k8s_api_core_v1_Pod_spec_priorityClassName == '?*'
	Require_StorageClass => (PersistVolumeClaim.io_k8s_api_core_v1_PersistentVolumeClaim_spec_storageClassName == '?*' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_volumeClaimTemplates_spec_storageClassName == '?*')
	Restrict_Annotations => (Deployment.io_k8s_api_apps_v1_Deployment_metadata_annotations_KeyMap == 'fluxcd_io' & Job.io_k8s_api_batch_v1_CronJob_metadata_annotations_KeyMap == 'fluxcd_io') | (Job.io_k8s_api_batch_v1_Job_metadata_annotations_KeyMap == 'fluxcd_io' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_metadata_annotations_KeyMap == 'fluxcd_io') | (DaemonSet.io_k8s_api_apps_v1_DaemonSet_metadata_annotations_KeyMap == 'fluxcd_io' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'fluxcd_io') | (Deployment.io_k8s_api_apps_v1_Deployment_metadata_annotations_ValueMap == '*?' & Job.io_k8s_api_batch_v1_CronJob_metadata_annotations_ValueMap == '*?') | (Job.io_k8s_api_batch_v1_Job_metadata_annotations_ValueMap == '*?' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_metadata_annotations_ValueMap == '*?') | (DaemonSet.io_k8s_api_apps_v1_DaemonSet_metadata_annotations_ValueMap == '*?' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap == '*?')
	Restrict_Auto_Mount_of_Service_Account_Tokens => !Pod.io_k8s_api_core_v1_Pod_spec_automountServiceAccountToken
	Restrict_Binding_to_Cluster_Admin => (RoleBinding.io_k8s_api_rbac_v1_RoleBinding_roleRef_name != 'cluster-admin' & ClusRole.io_k8s_api_rbac_v1_ClusterRoleBinding_roleRef_name != 'cluster-admin')
	Restrict_Binding_System_Groups => (RoleBinding.io_k8s_api_rbac_v1_RoleBinding_subjects_name != 'system:anonymous' & ClusRole.io_k8s_api_rbac_v1_ClusterRoleBinding_subjects_name != 'system:anonymous' & RoleBinding.io_k8s_api_rbac_v1_RoleBinding_subjects_name != 'system:unauthenticated' & ClusRole.io_k8s_api_rbac_v1_ClusterRoleBinding_subjects_name != 'system:unauthenticated' & RoleBinding.io_k8s_api_rbac_v1_RoleBinding_subjects_name != 'system:masters' & ClusRole.io_k8s_api_rbac_v1_ClusterRoleBinding_subjects_name != 'system:masters')
	Restrict_control_plane_scheduling => (Pod.io_k8s_api_core_v1_Pod_spec_tolerations_key != 'node-role_kubernetes_io/master' & Pod.io_k8s_api_core_v1_Pod_spec_tolerations_key != 'node-role_kubernetes_io/control-plane')
	Restrict_Ingress_Classes => (Ingress.io_k8s_api_networking_v1_Ingress_metadata_annotations_KeyMap == 'kubernetes_io/ingress_class' & Ingress.io_k8s_api_networking_v1_Ingress_metadata_annotations_ValueMap == 'HAProxy') | (Ingress.io_k8s_api_networking_v1_Ingress_metadata_annotations_KeyMap == 'kubernetes_io/ingress_class' & Ingress.io_k8s_api_networking_v1_Ingress_metadata_annotations_ValueMap == 'nginx')
	Restrict_Ingress_defaultBackend => !Ingress.io_k8s_api_networking_v1_Ingress_spec_defaultBackend
	Disallow_Service_Type_LoadBalancer => !Serv.io_k8s_api_core_v1_Service_spec_type_LoadBalancer
	Restrict_Node_Affinity => !Pod.io_k8s_api_core_v1_Pod_spec_affinity_nodeAffinity
	Restrict_node_selection => (!Pod.io_k8s_api_core_v1_Pod_spec_nodeSelector & !Pod.io_k8s_api_core_v1_Pod_spec_nodeName)
	Restrict_Auto_Mount_of_Service_Account_Tokens_in_Service_Account => !ServAcc.io_k8s_api_core_v1_ServiceAccount_automountServiceAccountToken
	Restrict_Service_Port_Range => (Serv.io_k8s_api_core_v1_Service_spec_ports_port > 31999 & Serv.io_k8s_api_core_v1_Service_spec_ports_port < 33001)
	Restrict_StorageClass => Kubernetes.io_k8s_api_storage_v1_StorageClass_reclaimPolicy == 'Delete'
	Validate_User_ID_Group_ID_and_FS_Group => (Pod.io_k8s_api_core_v1_Pod_spec_securityContext_runAsUser == 1000 & Pod.io_k8s_api_core_v1_Pod_spec_securityContext_runAsGroup == 3000 & Pod.io_k8s_api_core_v1_Pod_spec_securityContext_fsGroup == 2000)
	Disallow_Host_Namespaces => (!Pod.io_k8s_api_core_v1_Pod_spec_hostPID & !Pod.io_k8s_api_core_v1_Pod_spec_hostIPC & !Pod.io_k8s_api_core_v1_Pod_spec_hostNetwork)
	Disallow_hostPath => !Pod.io_k8s_api_core_v1_Pod_spec_volumes_hostPath
	Disallow_hostPorts_Range_Alternate => (((Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_ports_hostPort > 4999 & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_ports_hostPort < 6001) | Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_ports_hostPort == 0 ) & ((Pod.io_k8s_api_core_v1_Pod_spec_initContainers_ports_hostPort > 4999 & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_ports_hostPort < 6001) | Pod.io_k8s_api_core_v1_Pod_spec_initContainers_ports_hostPort == 0 ) & ((Pod.io_k8s_api_core_v1_Pod_spec_containers_ports_hostPort > 4999 & Pod.io_k8s_api_core_v1_Pod_spec_containers_ports_hostPort < 6001) | Pod.io_k8s_api_core_v1_Pod_spec_containers_ports_hostPort == 0 ))
	Disallow_hostPorts => (Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_ports_hostPort == 0 & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_ports_hostPort == 0 & Pod.io_k8s_api_core_v1_Pod_spec_containers_ports_hostPort == 0)
	Disallow_hostProcess => (!Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_windowsOptions_hostProcess & !Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_windowsOptions_hostProcess & !Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_windowsOptions_hostProcess)
	Disallow_Privilege_Escalation => (!Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_allowPrivilegeEscalation & !Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_allowPrivilegeEscalation & !Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_allowPrivilegeEscalation)
	Disallow_Privileged_Containers => (!Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_privileged & !Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_privileged & !Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_privileged)
	Disallow_procMount => (Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_procMount_nameStr == 'Default' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_procMount_nameStr == 'Default' & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_procMount_nameStr == 'Default')
	Require_Run_As_Non_Root_User => (Pod.io_k8s_api_core_v1_Pod_spec_securityContext_runAsUser > 0 & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_runAsUser > 0 & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_runAsUser > 0 & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_runAsUser > 0)
	Restrict_AppArmor => (Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'container_apparmor_security_beta_kubernetes_io' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap == 'runtime/default') | (Pod.io_k8s_api_core_v1_Pod_metadata_annotations_KeyMap == 'container_apparmor_security_beta_kubernetes_io' & Pod.io_k8s_api_core_v1_Pod_metadata_annotations_ValueMap == 'localhost')
	Restrict_Seccomp => ((!Pod.io_k8s_api_core_v1_Pod_spec_securityContext_seccompProfile_type | (Pod.io_k8s_api_core_v1_Pod_spec_securityContext_seccompProfile_type => Pod.io_k8s_api_core_v1_Pod_spec_securityContext_seccompProfile_type_RuntimeDefault | Pod.io_k8s_api_core_v1_Pod_spec_securityContext_seccompProfile_type_Localhost)) & (!Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_seccompProfile_type | (Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_seccompProfile_type => Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_seccompProfile_type_RuntimeDefault | Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_seccompProfile_type_Localhost)) & (!Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_seccompProfile_type | (Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_seccompProfile_type => Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_seccompProfile_type_RuntimeDefault | Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_seccompProfile_type_Localhost)) & (!Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_seccompProfile_type | (Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_seccompProfile_type => Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_seccompProfile_type_RuntimeDefault | Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_seccompProfile_type_Localhost)))
	Add_PSA_Namespace_Reporting => (Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_KeyMap == 'pod-security_kubernetes_io' & Kubernetes.io_k8s_api_core_v1_Namespace_metadata_labels_ValueMap == '?*')
	Check_supplementalGroups => (Pod.io_k8s_api_core_v1_Pod_spec_securityContext_supplementalGroups_IntegerValue > 99 & Pod.io_k8s_api_core_v1_Pod_spec_securityContext_supplementalGroups_IntegerValue < 201)
	Require_Run_As_ContainerUser_Windows => (Pod.io_k8s_api_core_v1_Pod_spec_securityContext_windowsOptions_runAsUserName == 'ContainerUser' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_windowsOptions_runAsUserName == 'ContainerUser' & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_windowsOptions_runAsUserName == 'ContainerUser')
	no_shared_ipc_namespace => !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_hostIPC & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_hostIPC & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_hostIPC & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_hostIPC & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_hostIPC & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_hostIPC & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_hostIPC
	no_host_network => !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_hostNetwork & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_hostNetwork & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_hostNetwork & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_hostNetwork & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_hostNetwork & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_hostNetwork & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_hostNetwork
	no_host_pid => !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_hostPID & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_hostPID & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_hostPID & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_hostPID & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_hostPID & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_hostPID & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_hostPID
	no_docker_sock_mount => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & Pod.io_k8s_api_core_v1_Pod_spec_volumes_hostPath_path != '/var/run/docker_sock' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_volumes_hostPath_path != '/var/run/docker_sock'
	no_privileged_containers => !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_privileged & !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_privileged & !CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_privileged & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_privileged & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_privileged & !DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_privileged & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_privileged & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_privileged & !Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_privileged & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_privileged & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_privileged & !Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_privileged & !Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_privileged & !Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_privileged & !Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_privileged & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_privileged & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_privileged & !ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_privileged & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_privileged & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_privileged & !RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_privileged & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_privileged & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_privileged & !StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_privileged
	no_auto_mount_service_token => !Pod.io_k8s_api_core_v1_Pod_spec_automountServiceAccountToken & !PodList.io_k8s_api_core_v1_PodList_items_spec_automountServiceAccountToken & !PodTemplate.io_k8s_api_core_v1_PodTemplate_template_spec_automountServiceAccountToken & !PodTemplateList.io_k8s_api_core_v1_PodTemplateList_items_template_spec_automountServiceAccountToken & !PodTemplateSpec.io_k8s_api_core_v1_PodTemplateSpec_spec_automountServiceAccountToken
	no_root => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_runAsNonRoot & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_runAsNonRoot & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_runAsNonRoot & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_runAsNonRoot & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_runAsNonRoot & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_runAsNonRoot & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_runAsNonRoot & Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_runAsNonRoot & Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_runAsNonRoot & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_runAsNonRoot & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_runAsNonRoot & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_runAsNonRoot & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_runAsNonRoot & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_runAsNonRoot & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_runAsNonRoot & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_runAsNonRoot & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_runAsNonRoot & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_runAsNonRoot
	use_high_gid => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_runAsGroup_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_runAsGroup_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_runAsGroup_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_runAsGroup_valueInt > 10000
	use_high_uid => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_runAsUser_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_runAsUser_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_runAsUser_valueInt > 10000 & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_runAsUser_valueInt > 10000
	no_sysadmin_capability => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_ADMIN'
	no_sysmodule_capability => CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & CronJob.io_k8s_api_batch_v1_CronJob_spec_jobTemplate_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Deployment.io_k8s_api_apps_v1_Deployment_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Job.io_k8s_api_batch_v1_Job_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Pod.io_k8s_api_core_v1_Pod_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & Pod.io_k8s_api_core_v1_Pod_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & RepController.io_k8s_api_core_v1_ReplicationController_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_containers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_initContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_spec_template_spec_ephemeralContainers_securityContext_capabilities_add_StringValue != 'SYS_MODULE'
	cpuLimitsMissing => Container.io_k8s_api_core_v1_Container_resources_limits
	cpuRequestsMissing => Container.io_k8s_api_core_v1_Container_resources_requests
	hpaMaxAvailability => HorizontalPodAutoscaler.io_k8s_api_autoscaling_v1_HorizontalPodAutoscaler_spec_maxReplicas > HorizontalPodAutoscaler.io_k8s_api_autoscaling_v1_HorizontalPodAutoscaler_spec_minReplicas & HorizontalPodAutoscaler.io_k8s_api_autoscaling_v1_HorizontalPodAutoscaler_spec_maxReplicas > 1
	hpaMinAvailability => HorizontalPodAutoscaler.io_k8s_api_autoscaling_v1_HorizontalPodAutoscaler_spec_minReplicas > 2
	livenessProbeMissing => Container.io_k8s_api_core_v1_Container_livenessProbe
	metadataAndInstanceMismatched => (Deployment.io_k8s_api_apps_v1_Deployment_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & Deployment.io_k8s_api_apps_v1_Deployment_metadata_labels_ValueMap == '_metadata_name') | (StatefulSet.io_k8s_api_apps_v1_StatefulSet_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & StatefulSet.io_k8s_api_apps_v1_StatefulSet_metadata_labels_ValueMap == '_metadata_name') | (DaemonSet.io_k8s_api_apps_v1_DaemonSet_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & DaemonSet.io_k8s_api_apps_v1_DaemonSet_metadata_labels_ValueMap == '_metadata_name') | (Job.io_k8s_api_batch_v1_Job_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & Job.io_k8s_api_batch_v1_Job_metadata_labels_ValueMap == '_metadata_name') | (CronJob.io_k8s_api_batch_v1_CronJob_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & CronJob.io_k8s_api_batch_v1_CronJob_metadata_labels_ValueMap == '_metadata_name') | (ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_metadata_labels_KeyMap == 'app_kubernetes_io/instance' & ReplicaSet.io_k8s_api_apps_v1_ReplicaSet_metadata_labels_ValueMap == '_metadata_name')
	pullPolicyNotAlways => (Container.io_k8s_api_core_v1_Container_imagePullPolicy_Always)
	readinessProbeMissing => Container.io_k8s_api_core_v1_Container_readinessProbe
	tagNotSpecified => (Container.io_k8s_api_core_v1_Container_image != '^+:latest$')
	topologySpreadConstraint => Pod.io_k8s_api_core_v1_Pod_spec_topologySpreadConstraints
	dangerousCapabilities => (Container.io_k8s_api_core_v1_Container_securityContext_capabilities_add_StringValue != 'ALL') & (Container.io_k8s_api_core_v1_Container_securityContext_capabilities_add_StringValue != 'SYS_ADMIN') & (Container.io_k8s_api_core_v1_Container_securityContext_capabilities_add_StringValue != 'NET_ADMIN')
	hostPortSet => Container.io_k8s_api_core_v1_Container_ports_hostPort == 0
	insecureCapabilities => (Container.io_k8s_api_core_v1_Container_securityContext_capabilities_drop_StringValue == 'ALL')
	linuxHardening => (Container.io_k8s_api_core_v1_Container_securityContext_seccompProfile_type_Unconfined)
	procMount => (Pod.io_k8s_api_core_v1_Pod_spec_containers_securityContext_procMount_StringValue == 'Default')
	tlsSettingsMissing => Ingress.io_k8s_api_networking_v1_Ingress_spec_tls